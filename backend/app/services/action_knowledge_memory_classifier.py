"""Action vs Knowledge Memory Classifier - Âü∫‰∫éAction vs KnowledgeÁöÑMemoryÂàÜÁ±ªÂô®"""

import json
import re
from typing import Any, Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

from openai import OpenAI

from app.core.config import settings


class MemoryCategory(Enum):
    """MemoryÂàÜÁ±ªÔºöÂü∫‰∫éAction vs Knowledge"""
    ACTION = "action"           # Á≥ªÁªüÂÅö‰∫Ü‰ªÄ‰πà (Episodic)
    KNOWLEDGE = "knowledge"     # Áî®Êà∑ÂÅèÂ•Ω/Áü•ËØÜ (Semantic)
    STATUS = "status"           # Áä∂ÊÄÅ‰ø°ÊÅØ (Episodic)
    PREFERENCE = "preference"   # Áî®Êà∑ÂÅèÂ•Ω (Semantic)


@dataclass
class ClassifiedMemory:
    """ÂàÜÁ±ªÂêéÁöÑMemory"""
    text: str
    category: MemoryCategory
    kind: str  # episodic, semantic, profile, commitment
    importance: float
    ttl_days: Optional[int]
    entities: List[str]
    confidence: float
    reasoning: str  # ÂàÜÁ±ªÂéüÂõ†


class ActionKnowledgeMemoryClassifier:
    """
    Âü∫‰∫éAction vs KnowledgeÁöÑMemoryÂàÜÁ±ªÂô®
    
    Ê†∏ÂøÉÁêÜÂøµÔºö
    - ACTION: Á≥ªÁªüÂÅö‰∫Ü‰ªÄ‰πàÔºåLLMÂÅö‰∫Ü‰ªÄ‰πà ‚Üí Episodic Memory
    - KNOWLEDGE: Áî®Êà∑ÂÅèÂ•Ω„ÄÅËßÑÂàô„ÄÅÁü•ËØÜ ‚Üí Semantic Memory
    """
    
    def __init__(self):
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = settings.OPENAI_MODEL
    
    def classify_memory(self, text: str, context: Optional[Dict] = None) -> ClassifiedMemory:
        """
        ÂàÜÁ±ªÂçï‰∏™MemoryÊñáÊú¨
        
        Args:
            text: MemoryÊñáÊú¨
            context: ‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºàÁî®Êà∑Êü•ËØ¢„ÄÅLLMÂìçÂ∫îÁ≠âÔºâ
            
        Returns:
            ClassifiedMemoryÂØπË±°
        """
        try:
            # ‰ΩøÁî®LLMËøõË°åÊô∫ËÉΩÂàÜÁ±ª
            classification_result = self._llm_classify(text, context)
            
            # ËΩ¨Êç¢‰∏∫Ê†áÂáÜÊ†ºÂºè
            return self._convert_to_classified_memory(text, classification_result)
            
        except Exception as e:
            print(f"Error in LLM classification: {e}")
            # FallbackÂà∞ËßÑÂàôÂàÜÁ±ª
            classification_result = self._rule_based_classify(text)
            return self._convert_to_classified_memory(text, classification_result)
    
    def _llm_classify(self, text: str, context: Optional[Dict] = None) -> Dict[str, Any]:
        """‰ΩøÁî®LLMËøõË°åÊô∫ËÉΩÂàÜÁ±ª"""
        
        system_prompt = """‰Ω†ÊòØ‰∏Ä‰∏™‰∏ì‰∏öÁöÑMemoryÂàÜÁ±ª‰∏ìÂÆ∂„ÄÇ‰Ω†ÁöÑ‰ªªÂä°ÊòØÂ∞ÜMemoryÊñáÊú¨ÂàÜÁ±ª‰∏∫ACTIONÊàñKNOWLEDGE„ÄÇ

ÂàÜÁ±ªÊ†áÂáÜÔºö
1. ACTION (Á≥ªÁªüÂÅö‰∫Ü‰ªÄ‰πà) ‚Üí episodic:
   - Á≥ªÁªüÊâßË°å‰∫ÜÊüê‰∏™Êìç‰Ωú (ÂèëÈÄÅÈÇÆ‰ª∂„ÄÅÂàõÂª∫ËÆ¢Âçï„ÄÅÊõ¥Êñ∞Áä∂ÊÄÅÁ≠â)
   - LLMÁîüÊàê‰∫ÜÊüê‰∏™ÂÜÖÂÆπ (ËçâÁ®ø„ÄÅÊä•Âëä„ÄÅÂª∫ËÆÆÁ≠â)
   - ÂÆåÊàê‰∫ÜÊüê‰∏™‰ªªÂä° (Â§ÑÁêÜ„ÄÅÊâßË°å„ÄÅÊìç‰ΩúÁ≠â)
   - Áä∂ÊÄÅÂèòÂåñ (ËÆ¢ÂçïÁä∂ÊÄÅ„ÄÅÂèëÁ•®Áä∂ÊÄÅÁ≠â)
   - Á§∫‰æã: "Email drafted for Kai Media", "Work order rescheduled", "Invoice sent"

2. KNOWLEDGE (Áî®Êà∑ÂÅèÂ•Ω/Áü•ËØÜ) ‚Üí semantic:
   - Áî®Êà∑Ë°®ËææÁöÑÂÅèÂ•Ω (ÂñúÊ¨¢„ÄÅ‰∏çÂñúÊ¨¢„ÄÅ‰π†ÊÉØÁ≠â)
   - ‰∏öÂä°ËßÑÂàôÂíåÁ≠ñÁï• (‰ªòÊ¨æÊù°‰ª∂„ÄÅ‰∫§‰ªòÂÅèÂ•ΩÁ≠â)
   - ÂÆ¢Êà∑‰ø°ÊÅØÂíåÁâπÂæÅ (Ë°å‰∏ö„ÄÅËßÑÊ®°„ÄÅÁâπÁÇπÁ≠â)
   - ÈïøÊúüÁü•ËØÜ (ÊîøÁ≠ñ„ÄÅÊµÅÁ®ã„ÄÅÊ†áÂáÜÁ≠â)
   - ÂåÖÂê´"Remember"„ÄÅ"prefer"„ÄÅ"like"Á≠âÂÖ≥ÈîÆËØçÁöÑËØ≠Âè•
   - Á§∫‰æã: "Remember: Kai Media prefers Friday deliveries", "TC Boiler is NET15", "Customer prefers ACH"

üî• Âº∫Âà∂ÂàÜÁ±ªËßÑÂàôÔºö
- ‰ªª‰ΩïÂåÖÂê´"Remember:"ÁöÑËØ≠Âè• ‚Üí KNOWLEDGE/semantic
- ‰ªª‰ΩïÂåÖÂê´"prefer"„ÄÅ"like"„ÄÅ"always"„ÄÅ"never"ÁöÑËØ≠Âè• ‚Üí KNOWLEDGE/semantic
- ‰ªª‰ΩïÂåÖÂê´"is NET"„ÄÅ"terms"„ÄÅ"payment"ÁöÑËØ≠Âè• ‚Üí KNOWLEDGE/semantic
- ‰ªª‰ΩïÂåÖÂê´"TC Boiler"„ÄÅ"Kai Media"Á≠âÂÆ¢Êà∑ÂêçÁß∞ÁöÑËØ≠Âè• ‚Üí KNOWLEDGE/semantic
- ‰ªª‰ΩïÂåÖÂê´"agreed"„ÄÅ"terms"„ÄÅ"NET15"„ÄÅ"ACH"ÁöÑËØ≠Âè• ‚Üí KNOWLEDGE/semantic

ËØ∑ÂàÜÊûê‰ª•‰∏ãMemoryÊñáÊú¨ÔºåÂπ∂ËøîÂõûJSONÊ†ºÂºèÁöÑÂàÜÁ±ªÁªìÊûúÔºö
{
    "category": "ACTION" Êàñ "KNOWLEDGE",
    "kind": "episodic" Êàñ "semantic",
    "importance": 0.0-1.0,
    "ttl_days": null Êàñ Êï∞Â≠ó,
    "reasoning": "ÂàÜÁ±ªÂéüÂõ†",
    "confidence": 0.0-1.0
}"""

        user_prompt = f"""MemoryÊñáÊú¨: "{text}"

‰∏ä‰∏ãÊñá‰ø°ÊÅØ: {context or "Êó†"}

ËØ∑ÂàÜÊûêËøô‰∏™MemoryÊñáÊú¨Â±û‰∫éACTIONËøòÊòØKNOWLEDGEÔºåÂπ∂ËØ¥ÊòéÂéüÂõ†„ÄÇ"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,
                max_tokens=500
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # Â∞ùËØïËß£ÊûêJSON
            try:
                # ÊèêÂèñJSONÈÉ®ÂàÜ
                json_start = result_text.find('{')
                json_end = result_text.rfind('}') + 1
                if json_start != -1 and json_end != -1:
                    json_text = result_text[json_start:json_end]
                    return json.loads(json_text)
            except json.JSONDecodeError:
                pass
            
            # Â¶ÇÊûúJSONËß£ÊûêÂ§±Ë¥•Ôºå‰ΩøÁî®ÊñáÊú¨ÂàÜÊûê
            return self._parse_text_classification(result_text)
            
        except Exception as e:
            print(f"LLM classification error: {e}")
            return self._rule_based_classify(text)
    
    def _parse_text_classification(self, text: str) -> Dict[str, Any]:
        """Ëß£ÊûêLLMÁöÑÊñáÊú¨ÂàÜÁ±ªÁªìÊûú"""
        text_lower = text.lower()
        
        # Âà§Êñ≠ÂàÜÁ±ª
        if "action" in text_lower:
            category = "ACTION"
            kind = "episodic"
            importance = 0.8
            ttl_days = 30
        elif "knowledge" in text_lower:
            category = "KNOWLEDGE"
            kind = "semantic"
            importance = 0.9
            ttl_days = None
        else:
            # ÈªòËÆ§ÂàÜÁ±ª
            category = "ACTION"
            kind = "episodic"
            importance = 0.7
            ttl_days = 30
        
        return {
            "category": category,
            "kind": kind,
            "importance": importance,
            "ttl_days": ttl_days,
            "reasoning": text[:100],
            "confidence": 0.7
        }
    
    def _rule_based_classify(self, text: str) -> Dict[str, Any]:
        """Âü∫‰∫éËßÑÂàôÁöÑÂàÜÁ±ªÔºàFallbackÔºâ"""
        text_lower = text.lower()
        
        # ACTIONÂÖ≥ÈîÆËØç
        action_keywords = [
            "drafted", "sent", "created", "completed", "finished", "done",
            "rescheduled", "updated", "processed", "executed", "performed",
            "email", "work order", "invoice", "order", "task"
        ]
        
        # KNOWLEDGEÂÖ≥ÈîÆËØç
        knowledge_keywords = [
            "prefers", "likes", "dislikes", "always", "never", "usually",
            "policy", "rule", "standard", "preference", "habit", "custom",
            "net15", "net30", "ach", "credit card", "friday", "monday"
        ]
        
        action_score = sum(1 for keyword in action_keywords if keyword in text_lower)
        knowledge_score = sum(1 for keyword in knowledge_keywords if keyword in text_lower)
        
        if action_score > knowledge_score:
            return {
                "category": "ACTION",
                "kind": "episodic",
                "importance": 0.8,
                "ttl_days": 30,
                "reasoning": f"Rule-based: ACTION keywords found ({action_score})",
                "confidence": 0.6
            }
        elif knowledge_score > action_score:
            return {
                "category": "KNOWLEDGE",
                "kind": "semantic",
                "importance": 0.9,
                "ttl_days": None,
                "reasoning": f"Rule-based: KNOWLEDGE keywords found ({knowledge_score})",
                "confidence": 0.6
            }
        else:
            # ÈªòËÆ§ÂàÜÁ±ª
            return {
                "category": "ACTION",
                "kind": "episodic",
                "importance": 0.7,
                "ttl_days": 30,
                "reasoning": "Rule-based: Default ACTION classification",
                "confidence": 0.5
            }
    
    def _convert_to_classified_memory(self, text: str, classification: Dict[str, Any]) -> ClassifiedMemory:
        """ËΩ¨Êç¢‰∏∫ClassifiedMemoryÂØπË±°"""
        
        # ÊèêÂèñÂÆû‰Ωì
        entities = self._extract_entities(text)
        
        # ÂÆâÂÖ®Âú∞ËΩ¨Êç¢category
        category_value = classification["category"].upper()
        if category_value == "ACTION":
            category = MemoryCategory.ACTION
        elif category_value == "KNOWLEDGE":
            category = MemoryCategory.KNOWLEDGE
        elif category_value == "STATUS":
            category = MemoryCategory.STATUS
        elif category_value == "PREFERENCE":
            category = MemoryCategory.PREFERENCE
        else:
            category = MemoryCategory.ACTION  # ÈªòËÆ§ÂÄº
        
        return ClassifiedMemory(
            text=text,
            category=category,
            kind=classification["kind"],
            importance=classification["importance"],
            ttl_days=classification["ttl_days"],
            entities=entities,
            confidence=classification["confidence"],
            reasoning=classification["reasoning"]
        )
    
    def _extract_entities(self, text: str) -> List[str]:
        """ÊèêÂèñÂÆû‰Ωì"""
        entities = []
        
        # ÂÆ¢Êà∑ÂêçÁß∞
        customer_pattern = r'\b([A-Z][a-z]+\s+[A-Z][a-z]+)\b'
        customers = re.findall(customer_pattern, text)
        entities.extend(customers)
        
        # ËÆ¢ÂçïÂè∑
        order_pattern = r'\b(SO-\d+|INV-\d+|WO-\d+)\b'
        orders = re.findall(order_pattern, text)
        entities.extend(orders)
        
        return list(set(entities))  # ÂéªÈáç
    
    def classify_batch(self, texts: List[str], context: Optional[Dict] = None) -> List[ClassifiedMemory]:
        """ÊâπÈáèÂàÜÁ±ª"""
        results = []
        for text in texts:
            classified = self.classify_memory(text, context)
            results.append(classified)
        return results
    
    def get_classification_stats(self, memories: List[ClassifiedMemory]) -> Dict[str, Any]:
        """Ëé∑ÂèñÂàÜÁ±ªÁªüËÆ°‰ø°ÊÅØ"""
        stats = {
            "total": len(memories),
            "action_count": 0,
            "knowledge_count": 0,
            "episodic_count": 0,
            "semantic_count": 0,
            "avg_confidence": 0.0
        }
        
        if not memories:
            return stats
        
        total_confidence = 0.0
        
        for memory in memories:
            if memory.category == MemoryCategory.ACTION:
                stats["action_count"] += 1
            elif memory.category == MemoryCategory.KNOWLEDGE:
                stats["knowledge_count"] += 1
            
            if memory.kind == "episodic":
                stats["episodic_count"] += 1
            elif memory.kind == "semantic":
                stats["semantic_count"] += 1
            
            total_confidence += memory.confidence
        
        stats["avg_confidence"] = total_confidence / len(memories)
        
        return stats


# ‰ΩøÁî®Á§∫‰æã
if __name__ == "__main__":
    classifier = ActionKnowledgeMemoryClassifier()
    
    # ÊµãËØïÁî®‰æã
    test_cases = [
        "Email drafted for Kai Media regarding invoice",
        "Kai Media prefers Friday deliveries",
        "Work order rescheduled for SO-1001",
        "TC Boiler is NET15 and prefers ACH",
        "Invoice sent to customer",
        "Customer prefers morning deliveries"
    ]
    
    print("=== Action vs Knowledge Memory Classification Test ===")
    
    for text in test_cases:
        result = classifier.classify_memory(text)
        print(f"\nText: {text}")
        print(f"Category: {result.category.value}")
        print(f"Kind: {result.kind}")
        print(f"Importance: {result.importance}")
        print(f"TTL: {result.ttl_days}")
        print(f"Confidence: {result.confidence}")
        print(f"Reasoning: {result.reasoning}")
        print("-" * 50)
